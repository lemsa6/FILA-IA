APP_NAME=Laravel
APP_ENV=local
APP_KEY=
APP_DEBUG=true
APP_URL=http://localhost

APP_LOCALE=en
APP_FALLBACK_LOCALE=en
APP_FAKER_LOCALE=en_US

APP_MAINTENANCE_DRIVER=file
# APP_MAINTENANCE_STORE=database

PHP_CLI_SERVER_WORKERS=4

BCRYPT_ROUNDS=12

LOG_CHANNEL=stack
LOG_STACK=single
LOG_DEPRECATIONS_CHANNEL=null
LOG_LEVEL=debug

DB_CONNECTION=sqlite
# DB_HOST=127.0.0.1
# DB_PORT=3306
# DB_DATABASE=laravel
# DB_USERNAME=root
# DB_PASSWORD=

SESSION_DRIVER=database
SESSION_LIFETIME=120
SESSION_ENCRYPT=false
SESSION_PATH=/
SESSION_DOMAIN=null

BROADCAST_CONNECTION=log
FILESYSTEM_DISK=local
QUEUE_CONNECTION=database

CACHE_STORE=database
# CACHE_PREFIX=

MEMCACHED_HOST=127.0.0.1

REDIS_CLIENT=phpredis
REDIS_HOST=127.0.0.1
REDIS_PASSWORD=null
REDIS_PORT=6379

MAIL_MAILER=log
MAIL_SCHEME=null
MAIL_HOST=127.0.0.1
MAIL_PORT=2525
MAIL_USERNAME=null
MAIL_PASSWORD=null
MAIL_FROM_ADDRESS="hello@example.com"
MAIL_FROM_NAME="${APP_NAME}"

AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_DEFAULT_REGION=us-east-1
AWS_BUCKET=
AWS_USE_PATH_STYLE_ENDPOINT=false

VITE_APP_NAME="${APP_NAME}"

# Configurações do Ollama (mantidas para compatibilidade)
OLLAMA_API_URL=http://host.docker.internal:11434/api
OLLAMA_MODEL=qwen2.5vl:7b
OLLAMA_CIRCUIT_BREAKER_THRESHOLD=5
OLLAMA_CIRCUIT_BREAKER_TIMEOUT=60
OLLAMA_CACHE_TTL=3600

# Configurações OpenAI (IA Principal)
OPENAI_API_KEY=sua_chave_openai_aqui
OPENAI_MODEL=gpt-5-nano
OPENAI_API_URL=https://api.openai.com/v1
OPENAI_ORGANIZATION=sua_organizacao_opcional
OPENAI_CIRCUIT_BREAKER_THRESHOLD=3
OPENAI_CIRCUIT_BREAKER_TIMEOUT=30
OPENAI_CACHE_TTL=3600
